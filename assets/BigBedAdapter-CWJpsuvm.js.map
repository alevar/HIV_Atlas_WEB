{"version":3,"file":"BigBedAdapter-CWJpsuvm.js","sources":["../../node_modules/@gmod/bbi/esm/bigbed.js","../../node_modules/@jbrowse/plugin-bed/esm/BigBedAdapter/BigBedAdapter.js"],"sourcesContent":["import { Buffer } from 'buffer';\nimport { Observable, merge, firstValueFrom } from 'rxjs';\nimport { map, reduce } from 'rxjs/operators';\nimport AbortablePromiseCache from '@gmod/abortable-promise-cache';\nimport QuickLRU from 'quick-lru';\n// locals\nimport { BBI } from './bbi';\nexport function filterUndef(ts) {\n    return ts.filter((t) => !!t);\n}\nexport class BigBed extends BBI {\n    constructor() {\n        super(...arguments);\n        this.readIndicesCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: 1 }),\n            fill: (args, signal) => this._readIndices({ ...args, signal }),\n        });\n    }\n    readIndices(opts = {}) {\n        const { signal, ...rest } = opts;\n        return this.readIndicesCache.get(JSON.stringify(rest), opts, signal);\n    }\n    /*\n     * retrieve unzoomed view for any scale\n     */\n    async getView(_scale, opts) {\n        return this.getUnzoomedView(opts);\n    }\n    /*\n     * parse the bigbed extraIndex fields\n     *\n     *\n     * @return a Promise for an array of Index data structure since there can be\n     * multiple extraIndexes in a bigbed, see bedToBigBed documentation\n     */\n    async _readIndices(opts) {\n        const { extHeaderOffset, isBigEndian } = await this.getHeader(opts);\n        const { buffer: data } = await this.bbi.read(Buffer.alloc(64), 0, 64, Number(extHeaderOffset));\n        const le = !isBigEndian;\n        const b = data;\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        // const _size = dataView.getUint16(offset, le)\n        offset += 2;\n        const count = dataView.getUint16(offset, le);\n        offset += 2;\n        const dataOffset = Number(dataView.getBigUint64(offset, le));\n        offset += 8;\n        // no extra index is defined if count==0\n        if (count === 0) {\n            return [];\n        }\n        const blocklen = 20;\n        const len = blocklen * count;\n        const { buffer } = await this.bbi.read(Buffer.alloc(len), 0, len, Number(dataOffset));\n        const indices = [];\n        for (let i = 0; i < count; i += 1) {\n            const b = buffer.subarray(i * blocklen);\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            let offset = 0;\n            const type = dataView.getInt16(offset, le);\n            offset += 2;\n            const fieldcount = dataView.getInt16(offset, le);\n            offset += 2;\n            const dataOffset = Number(dataView.getBigUint64(offset, le));\n            offset += 8 + 4; //4 skip\n            const field = dataView.getInt16(offset, le);\n            indices.push({ type, fieldcount, offset: Number(dataOffset), field });\n        }\n        return indices;\n    }\n    /*\n     * perform a search in the bigbed extraIndex to find which blocks in the\n     * bigbed data to look for the actual feature data\n     *\n     * @param name - the name to search for\n     * @param opts - a SearchOptions argument with optional signal\n     * @return a Promise for an array of bigbed block Loc entries\n     */\n    async searchExtraIndexBlocks(name, opts = {}) {\n        const { isBigEndian } = await this.getHeader(opts);\n        const indices = await this.readIndices(opts);\n        if (indices.length === 0) {\n            return [];\n        }\n        const locs = indices.map(async (index) => {\n            const { offset: offset2, field } = index;\n            const { buffer: data } = await this.bbi.read(Buffer.alloc(32), 0, 32, offset2, opts);\n            const le = !isBigEndian;\n            const b = data;\n            const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n            let offset = 0;\n            // const _magic = dataView.getInt32(offset, le)\n            offset += 4;\n            const blockSize = dataView.getInt32(offset, le);\n            offset += 4;\n            const keySize = dataView.getInt32(offset, le);\n            offset += 4;\n            const valSize = dataView.getInt32(offset, le);\n            offset += 4;\n            // const _itemCount = Number(dataView.getBigUint64(offset, le))\n            offset += 8;\n            const bptReadNode = async (nodeOffset) => {\n                const val = Number(nodeOffset);\n                const len = 4 + blockSize * (keySize + valSize);\n                const { buffer } = await this.bbi.read(Buffer.alloc(len), 0, len, val, opts);\n                const b = buffer;\n                const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n                let offset = 0;\n                const nodeType = dataView.getInt8(offset);\n                offset += 2; //skip 1\n                const cnt = dataView.getInt16(offset, le);\n                offset += 2;\n                const keys = [];\n                if (nodeType === 0) {\n                    const leafkeys = [];\n                    for (let i = 0; i < cnt; i++) {\n                        const key = b\n                            .subarray(offset, offset + keySize)\n                            .toString()\n                            .replaceAll('\\0', '');\n                        offset += keySize;\n                        const dataOffset = Number(dataView.getBigUint64(offset, le));\n                        offset += 8;\n                        leafkeys.push({ key, offset: dataOffset });\n                    }\n                    let lastOffset = 0;\n                    for (const { key, offset } of leafkeys) {\n                        if (name.localeCompare(key) < 0 && lastOffset) {\n                            return bptReadNode(lastOffset);\n                        }\n                        lastOffset = offset;\n                    }\n                    return bptReadNode(lastOffset);\n                }\n                else if (nodeType === 1) {\n                    for (let i = 0; i < cnt; i++) {\n                        const key = b\n                            .subarray(offset, offset + keySize)\n                            .toString()\n                            .replaceAll('\\0', '');\n                        offset += keySize;\n                        const dataOffset = Number(dataView.getBigUint64(offset, le));\n                        offset += 8;\n                        const length = dataView.getUint32(offset, le);\n                        offset += 4;\n                        const reserved = dataView.getUint32(offset, le);\n                        offset += 4;\n                        keys.push({ key, offset: dataOffset, length, reserved });\n                    }\n                    for (const n of keys) {\n                        if (n.key === name) {\n                            return { ...n, field };\n                        }\n                    }\n                    return undefined;\n                }\n            };\n            const rootNodeOffset = 32;\n            return bptReadNode(offset2 + rootNodeOffset);\n        });\n        return filterUndef(await Promise.all(locs));\n    }\n    /*\n     * retrieve the features from the bigbed data that were found through the\n     * lookup of the extraIndex note that there can be multiple extraIndex, see\n     * the BigBed specification and the -extraIndex argument to bedToBigBed\n     *\n     * @param name - the name to search for\n     * @param opts - a SearchOptions argument with optional signal\n     * @return a Promise for an array of Feature\n     */\n    async searchExtraIndex(name, opts = {}) {\n        const blocks = await this.searchExtraIndexBlocks(name, opts);\n        if (blocks.length === 0) {\n            return [];\n        }\n        const view = await this.getUnzoomedView(opts);\n        const res = blocks.map(block => {\n            return new Observable(observer => {\n                view.readFeatures(observer, [block], opts).catch((e) => {\n                    observer.error(e);\n                });\n            }).pipe(reduce((acc, curr) => acc.concat(curr)), map(x => {\n                for (const element of x) {\n                    element.field = block.field;\n                }\n                return x;\n            }));\n        });\n        const ret = await firstValueFrom(merge(...res));\n        return ret.filter(f => { var _a; return ((_a = f.rest) === null || _a === void 0 ? void 0 : _a.split('\\t')[(f.field || 0) - 3]) === name; });\n    }\n}\n//# sourceMappingURL=bigbed.js.map","import { BigBed } from '@gmod/bbi';\nimport BED from '@gmod/bed';\nimport { BaseFeatureDataAdapter, } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { openLocation } from '@jbrowse/core/util/io';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport { doesIntersect2, max, min, SimpleFeature, } from '@jbrowse/core/util';\n// locals\nimport { isUcscProcessedTranscript, makeBlocks, ucscProcessedTranscript, } from '../util';\nexport default class BigBedAdapter extends BaseFeatureDataAdapter {\n    async configurePre(opts) {\n        const pm = this.pluginManager;\n        const bigbed = new BigBed({\n            filehandle: openLocation(this.getConf('bigBedLocation'), pm),\n        });\n        const header = await bigbed.getHeader(opts);\n        const parser = new BED({ autoSql: header.autoSql });\n        return { bigbed, header, parser };\n    }\n    async configure(opts) {\n        if (!this.cached) {\n            this.cached = this.configurePre(opts).catch((e) => {\n                this.cached = undefined;\n                throw e;\n            });\n        }\n        return this.cached;\n    }\n    async getRefNames(opts) {\n        const { header } = await this.configure(opts);\n        return Object.keys(header.refsByName);\n    }\n    async getHeader(opts) {\n        const { parser, header } = await this.configure(opts);\n        const { version, fileType } = header;\n        const { fields, ...rest } = parser.autoSql;\n        return {\n            version,\n            fileType,\n            autoSql: { ...rest },\n            fields: Object.fromEntries(fields.map(({ name, comment }) => [name, comment])),\n        };\n    }\n    async getFeaturesHelper(query, opts, observer, allowRedispatch, originalQuery = query) {\n        const { signal } = opts;\n        const scoreColumn = this.getConf('scoreColumn');\n        const aggregateField = this.getConf('aggregateField');\n        const { parser, bigbed } = await this.configure(opts);\n        const feats = await bigbed.getFeatures(query.refName, query.start, query.end, {\n            signal,\n            basesPerSpan: query.end - query.start,\n        });\n        if (allowRedispatch && feats.length) {\n            let minStart = Number.POSITIVE_INFINITY;\n            let maxEnd = Number.NEGATIVE_INFINITY;\n            for (const feat of feats) {\n                if (feat.start < minStart) {\n                    minStart = feat.start;\n                }\n                if (feat.end > maxEnd) {\n                    maxEnd = feat.end;\n                }\n            }\n            if (maxEnd > query.end || minStart < query.start) {\n                await this.getFeaturesHelper({ ...query, start: minStart, end: maxEnd }, opts, observer, false, query);\n                return;\n            }\n        }\n        const parentAggregation = {};\n        if (feats.some(f => f.uniqueId === undefined)) {\n            throw new Error('found uniqueId undefined');\n        }\n        for (const feat of feats) {\n            const data = parser.parseLine(`${query.refName}\\t${feat.start}\\t${feat.end}\\t${feat.rest}`, { uniqueId: feat.uniqueId });\n            const aggr = data[aggregateField];\n            if (!parentAggregation[aggr]) {\n                parentAggregation[aggr] = [];\n            }\n            const { uniqueId, type, chromStart, chromStarts, blockStarts, blockCount, blockSizes, chromEnd, thickStart, thickEnd, chrom, score, ...rest } = data;\n            const subfeatures = blockCount\n                ? makeBlocks({\n                    chromStarts,\n                    blockStarts,\n                    blockCount,\n                    blockSizes,\n                    uniqueId,\n                    refName: query.refName,\n                    start: feat.start,\n                })\n                : [];\n            if (isUcscProcessedTranscript(data)) {\n                const f = ucscProcessedTranscript({\n                    ...rest,\n                    uniqueId,\n                    type,\n                    start: feat.start,\n                    end: feat.end,\n                    refName: query.refName,\n                    score: scoreColumn ? +data[scoreColumn] : score,\n                    chromStarts,\n                    blockCount,\n                    blockSizes,\n                    thickStart,\n                    thickEnd,\n                    subfeatures,\n                });\n                if (aggr) {\n                    parentAggregation[aggr].push(f);\n                }\n                else {\n                    if (doesIntersect2(f.start, f.end, originalQuery.start, originalQuery.end)) {\n                        observer.next(new SimpleFeature({ id: `${this.id}-${uniqueId}`, data: f }));\n                    }\n                }\n            }\n            else {\n                if (doesIntersect2(feat.start, feat.end, originalQuery.start, originalQuery.end)) {\n                    observer.next(new SimpleFeature({\n                        id: `${this.id}-${uniqueId}`,\n                        data: {\n                            ...rest,\n                            uniqueId,\n                            type,\n                            start: feat.start,\n                            score: scoreColumn ? +data[scoreColumn] : score,\n                            end: feat.end,\n                            refName: query.refName,\n                            subfeatures,\n                        },\n                    }));\n                }\n            }\n        }\n        Object.entries(parentAggregation).map(([name, subfeatures]) => {\n            const s = min(subfeatures.map(f => f.start));\n            const e = max(subfeatures.map(f => f.end));\n            if (doesIntersect2(s, e, originalQuery.start, originalQuery.end)) {\n                const { uniqueId, strand } = subfeatures[0];\n                observer.next(new SimpleFeature({\n                    id: `${this.id}-${uniqueId}-parent`,\n                    data: {\n                        type: 'gene',\n                        subfeatures,\n                        strand,\n                        name,\n                        start: s,\n                        end: e,\n                        refName: query.refName,\n                    },\n                }));\n            }\n        });\n        observer.complete();\n    }\n    getFeatures(query, opts = {}) {\n        return ObservableCreate(async (observer) => {\n            try {\n                await this.getFeaturesHelper(query, opts, observer, true);\n            }\n            catch (e) {\n                observer.error(e);\n            }\n        }, opts.signal);\n    }\n    freeResources() { }\n}\n"],"names":["filterUndef","ts","t","BigBed","BBI","AbortablePromiseCache","QuickLRU","args","signal","opts","rest","_scale","extHeaderOffset","isBigEndian","data","Buffer","le","b","dataView","offset","count","dataOffset","blocklen","len","buffer","indices","i","type","fieldcount","field","name","locs","index","offset2","blockSize","keySize","valSize","bptReadNode","nodeOffset","val","nodeType","cnt","keys","leafkeys","key","lastOffset","length","reserved","n","blocks","view","res","block","Observable","observer","e","reduce","acc","curr","map","x","element","firstValueFrom","merge","_a","BigBedAdapter","BaseFeatureDataAdapter","pm","bigbed","openLocation","header","parser","BED","version","fileType","fields","comment","query","allowRedispatch","originalQuery","scoreColumn","aggregateField","feats","minStart","maxEnd","feat","parentAggregation","f","aggr","uniqueId","chromStart","chromStarts","blockStarts","blockCount","blockSizes","chromEnd","thickStart","thickEnd","chrom","score","subfeatures","makeBlocks","isUcscProcessedTranscript","ucscProcessedTranscript","doesIntersect2","SimpleFeature","s","min","max","strand","ObservableCreate"],"mappings":"8NAOO,SAASA,EAAYC,EAAI,CAC5B,OAAOA,EAAG,OAAQC,GAAM,CAAC,CAACA,CAAC,CAC/B,CACO,MAAMC,UAAeC,CAAI,CAC5B,aAAc,CACV,MAAM,GAAG,SAAS,EAClB,KAAK,iBAAmB,IAAIC,EAAsB,CAC9C,MAAO,IAAIC,EAAS,CAAE,QAAS,CAAC,CAAE,EAClC,KAAM,CAACC,EAAMC,IAAW,KAAK,aAAa,CAAE,GAAGD,EAAM,OAAAC,EAAQ,CACzE,CAAS,CACT,CACI,YAAYC,EAAO,GAAI,CACnB,KAAM,CAAE,OAAAD,EAAQ,GAAGE,CAAI,EAAKD,EAC5B,OAAO,KAAK,iBAAiB,IAAI,KAAK,UAAUC,CAAI,EAAGD,EAAMD,CAAM,CAC3E,CAII,MAAM,QAAQG,EAAQF,EAAM,CACxB,OAAO,KAAK,gBAAgBA,CAAI,CACxC,CAQI,MAAM,aAAaA,EAAM,CACrB,KAAM,CAAE,gBAAAG,EAAiB,YAAAC,CAAW,EAAK,MAAM,KAAK,UAAUJ,CAAI,EAC5D,CAAE,OAAQK,CAAI,EAAK,MAAM,KAAK,IAAI,KAAKC,EAAM,OAAC,MAAM,EAAE,EAAG,EAAG,GAAI,OAAOH,CAAe,CAAC,EACvFI,EAAK,CAACH,EACNI,EAAIH,EACJI,EAAW,IAAI,SAASD,EAAE,OAAQA,EAAE,WAAYA,EAAE,MAAM,EAC9D,IAAIE,EAAS,EAEbA,GAAU,EACV,MAAMC,EAAQF,EAAS,UAAUC,EAAQH,CAAE,EAC3CG,GAAU,EACV,MAAME,EAAa,OAAOH,EAAS,aAAaC,EAAQH,CAAE,CAAC,EAG3D,GAFAG,GAAU,EAENC,IAAU,EACV,MAAO,CAAE,EAEb,MAAME,EAAW,GACXC,EAAMD,EAAWF,EACjB,CAAEI,OAAAA,CAAQ,EAAG,MAAM,KAAK,IAAI,KAAKT,EAAAA,OAAO,MAAMQ,CAAG,EAAG,EAAGA,EAAK,OAAOF,CAAU,CAAC,EAC9EI,EAAU,CAAE,EAClB,QAASC,EAAI,EAAGA,EAAIN,EAAOM,GAAK,EAAG,CAC/B,MAAMT,EAAIO,EAAO,SAASE,EAAIJ,CAAQ,EAChCJ,EAAW,IAAI,SAASD,EAAE,OAAQA,EAAE,WAAYA,EAAE,MAAM,EAC9D,IAAIE,EAAS,EACb,MAAMQ,EAAOT,EAAS,SAASC,EAAQH,CAAE,EACzCG,GAAU,EACV,MAAMS,EAAaV,EAAS,SAASC,EAAQH,CAAE,EAC/CG,GAAU,EACV,MAAME,EAAa,OAAOH,EAAS,aAAaC,EAAQH,CAAE,CAAC,EAC3DG,GAAU,GACV,MAAMU,EAAQX,EAAS,SAASC,EAAQH,CAAE,EAC1CS,EAAQ,KAAK,CAAE,KAAAE,EAAM,WAAAC,EAAY,OAAQ,OAAOP,CAAU,EAAG,MAAAQ,EAAO,CAChF,CACQ,OAAOJ,CACf,CASI,MAAM,uBAAuBK,EAAMrB,EAAO,GAAI,CAC1C,KAAM,CAAE,YAAAI,CAAa,EAAG,MAAM,KAAK,UAAUJ,CAAI,EAC3CgB,EAAU,MAAM,KAAK,YAAYhB,CAAI,EAC3C,GAAIgB,EAAQ,SAAW,EACnB,MAAO,CAAE,EAEb,MAAMM,EAAON,EAAQ,IAAI,MAAOO,GAAU,CACtC,KAAM,CAAE,OAAQC,EAAS,MAAAJ,CAAO,EAAGG,EAC7B,CAAE,OAAQlB,CAAI,EAAK,MAAM,KAAK,IAAI,KAAKC,EAAM,OAAC,MAAM,EAAE,EAAG,EAAG,GAAIkB,EAASxB,CAAI,EAC7EO,EAAK,CAACH,EACNI,EAAIH,EACJI,EAAW,IAAI,SAASD,EAAE,OAAQA,EAAE,WAAYA,EAAE,MAAM,EAC9D,IAAIE,EAAS,EAEbA,GAAU,EACV,MAAMe,EAAYhB,EAAS,SAASC,EAAQH,CAAE,EAC9CG,GAAU,EACV,MAAMgB,EAAUjB,EAAS,SAASC,EAAQH,CAAE,EAC5CG,GAAU,EACV,MAAMiB,EAAUlB,EAAS,SAASC,EAAQH,CAAE,EAC5CG,GAAU,EAEVA,GAAU,EACV,MAAMkB,EAAc,MAAOC,GAAe,CACtC,MAAMC,EAAM,OAAOD,CAAU,EACvBf,EAAM,EAAIW,GAAaC,EAAUC,GACjC,CAAEZ,OAAAA,CAAQ,EAAG,MAAM,KAAK,IAAI,KAAKT,EAAAA,OAAO,MAAMQ,CAAG,EAAG,EAAGA,EAAKgB,EAAK9B,CAAI,EACrEQ,EAAIO,EACJN,EAAW,IAAI,SAASD,EAAE,OAAQA,EAAE,WAAYA,EAAE,MAAM,EAC9D,IAAIE,EAAS,EACb,MAAMqB,EAAWtB,EAAS,QAAQC,CAAM,EACxCA,GAAU,EACV,MAAMsB,EAAMvB,EAAS,SAASC,EAAQH,CAAE,EACxCG,GAAU,EACV,MAAMuB,EAAO,CAAE,EACf,GAAIF,IAAa,EAAG,CAChB,MAAMG,EAAW,CAAE,EACnB,QAASjB,EAAI,EAAGA,EAAIe,EAAKf,IAAK,CAC1B,MAAMkB,EAAM3B,EACP,SAASE,EAAQA,EAASgB,CAAO,EACjC,SAAQ,EACR,WAAW,KAAM,EAAE,EACxBhB,GAAUgB,EACV,MAAMd,EAAa,OAAOH,EAAS,aAAaC,EAAQH,CAAE,CAAC,EAC3DG,GAAU,EACVwB,EAAS,KAAK,CAAE,IAAAC,EAAK,OAAQvB,CAAU,CAAE,CACjE,CACoB,IAAIwB,EAAa,EACjB,SAAW,CAAE,IAAAD,EAAK,OAAAzB,CAAM,IAAMwB,EAAU,CACpC,GAAIb,EAAK,cAAcc,CAAG,EAAI,GAAKC,EAC/B,OAAOR,EAAYQ,CAAU,EAEjCA,EAAa1B,CACrC,CACoB,OAAOkB,EAAYQ,CAAU,CACjD,SACyBL,IAAa,EAAG,CACrB,QAASd,EAAI,EAAGA,EAAIe,EAAKf,IAAK,CAC1B,MAAMkB,EAAM3B,EACP,SAASE,EAAQA,EAASgB,CAAO,EACjC,SAAQ,EACR,WAAW,KAAM,EAAE,EACxBhB,GAAUgB,EACV,MAAMd,EAAa,OAAOH,EAAS,aAAaC,EAAQH,CAAE,CAAC,EAC3DG,GAAU,EACV,MAAM2B,EAAS5B,EAAS,UAAUC,EAAQH,CAAE,EAC5CG,GAAU,EACV,MAAM4B,EAAW7B,EAAS,UAAUC,EAAQH,CAAE,EAC9CG,GAAU,EACVuB,EAAK,KAAK,CAAE,IAAAE,EAAK,OAAQvB,EAAY,OAAAyB,EAAQ,SAAAC,EAAU,CAC/E,CACoB,UAAWC,KAAKN,EACZ,GAAIM,EAAE,MAAQlB,EACV,MAAO,CAAE,GAAGkB,EAAG,MAAAnB,CAAO,EAG9B,MACpB,CACa,EAED,OAAOQ,EAAYJ,EADI,EACoB,CACvD,CAAS,EACD,OAAOjC,EAAY,MAAM,QAAQ,IAAI+B,CAAI,CAAC,CAClD,CAUI,MAAM,iBAAiBD,EAAMrB,EAAO,GAAI,CACpC,MAAMwC,EAAS,MAAM,KAAK,uBAAuBnB,EAAMrB,CAAI,EAC3D,GAAIwC,EAAO,SAAW,EAClB,MAAO,CAAE,EAEb,MAAMC,EAAO,MAAM,KAAK,gBAAgBzC,CAAI,EACtC0C,EAAMF,EAAO,IAAIG,GACZ,IAAIC,EAAWC,GAAY,CAC9BJ,EAAK,aAAaI,EAAU,CAACF,CAAK,EAAG3C,CAAI,EAAE,MAAO8C,GAAM,CACpDD,EAAS,MAAMC,CAAC,CACpC,CAAiB,CACJ,CAAA,EAAE,KAAKC,EAAO,CAACC,EAAKC,IAASD,EAAI,OAAOC,CAAI,CAAC,EAAGC,EAAIC,GAAK,CACtD,UAAWC,KAAWD,EAClBC,EAAQ,MAAQT,EAAM,MAE1B,OAAOQ,CACvB,CAAa,CAAC,CACL,EAED,OADY,MAAME,EAAeC,EAAM,GAAGZ,CAAG,CAAC,GACnC,OAAO,GAAK,CAAE,IAAIa,EAAI,QAASA,EAAK,EAAE,QAAU,MAAQA,IAAO,OAAS,OAASA,EAAG,MAAM,GAAI,GAAG,EAAE,OAAS,GAAK,CAAC,KAAOlC,CAAK,CAAE,CACnJ,CACA,CCzLe,MAAMmC,WAAsBC,EAAAA,sBAAuB,CAC9D,MAAM,aAAazD,EAAM,CACrB,MAAM0D,EAAK,KAAK,cACVC,EAAS,IAAIjE,EAAO,CACtB,WAAYkE,EAAY,aAAC,KAAK,QAAQ,gBAAgB,EAAGF,CAAE,CACvE,CAAS,EACKG,EAAS,MAAMF,EAAO,UAAU3D,CAAI,EACpC8D,EAAS,IAAIC,EAAI,CAAE,QAASF,EAAO,QAAS,EAClD,MAAO,CAAE,OAAAF,EAAQ,OAAAE,EAAQ,OAAAC,CAAQ,CACzC,CACI,MAAM,UAAU9D,EAAM,CAClB,OAAK,KAAK,SACN,KAAK,OAAS,KAAK,aAAaA,CAAI,EAAE,MAAO8C,GAAM,CAC/C,WAAK,OAAS,OACRA,CACtB,CAAa,GAEE,KAAK,MACpB,CACI,MAAM,YAAY9C,EAAM,CACpB,KAAM,CAAE,OAAA6D,CAAQ,EAAG,MAAM,KAAK,UAAU7D,CAAI,EAC5C,OAAO,OAAO,KAAK6D,EAAO,UAAU,CAC5C,CACI,MAAM,UAAU7D,EAAM,CAClB,KAAM,CAAE,OAAA8D,EAAQ,OAAAD,CAAM,EAAK,MAAM,KAAK,UAAU7D,CAAI,EAC9C,CAAE,QAAAgE,EAAS,SAAAC,CAAQ,EAAKJ,EACxB,CAAE,OAAAK,EAAQ,GAAGjE,CAAM,EAAG6D,EAAO,QACnC,MAAO,CACH,QAAAE,EACA,SAAAC,EACA,QAAS,CAAE,GAAGhE,CAAM,EACpB,OAAQ,OAAO,YAAYiE,EAAO,IAAI,CAAC,CAAE,KAAA7C,EAAM,QAAA8C,CAAO,IAAO,CAAC9C,EAAM8C,CAAO,CAAC,CAAC,CAChF,CACT,CACI,MAAM,kBAAkBC,EAAOpE,EAAM6C,EAAUwB,EAAiBC,EAAgBF,EAAO,CACnF,KAAM,CAAE,OAAArE,CAAM,EAAKC,EACbuE,EAAc,KAAK,QAAQ,aAAa,EACxCC,EAAiB,KAAK,QAAQ,gBAAgB,EAC9C,CAAE,OAAAV,EAAQ,OAAAH,CAAM,EAAK,MAAM,KAAK,UAAU3D,CAAI,EAC9CyE,EAAQ,MAAMd,EAAO,YAAYS,EAAM,QAASA,EAAM,MAAOA,EAAM,IAAK,CAC1E,OAAArE,EACA,aAAcqE,EAAM,IAAMA,EAAM,KAC5C,CAAS,EACD,GAAIC,GAAmBI,EAAM,OAAQ,CACjC,IAAIC,EAAW,OAAO,kBAClBC,EAAS,OAAO,kBACpB,UAAWC,KAAQH,EACXG,EAAK,MAAQF,IACbA,EAAWE,EAAK,OAEhBA,EAAK,IAAMD,IACXA,EAASC,EAAK,KAGtB,GAAID,EAASP,EAAM,KAAOM,EAAWN,EAAM,MAAO,CAC9C,MAAM,KAAK,kBAAkB,CAAE,GAAGA,EAAO,MAAOM,EAAU,IAAKC,CAAM,EAAI3E,EAAM6C,EAAU,GAAOuB,CAAK,EACrG,MAChB,CACA,CACQ,MAAMS,EAAoB,CAAE,EAC5B,GAAIJ,EAAM,KAAKK,GAAKA,EAAE,WAAa,MAAS,EACxC,MAAM,IAAI,MAAM,0BAA0B,EAE9C,UAAWF,KAAQH,EAAO,CACtB,MAAMpE,EAAOyD,EAAO,UAAU,GAAGM,EAAM,OAAO,IAAKQ,EAAK,KAAK,IAAKA,EAAK,GAAG,IAAKA,EAAK,IAAI,GAAI,CAAE,SAAUA,EAAK,SAAU,EACjHG,EAAO1E,EAAKmE,CAAc,EAC3BK,EAAkBE,CAAI,IACvBF,EAAkBE,CAAI,EAAI,CAAE,GAEhC,KAAM,CAAE,SAAAC,EAAU,KAAA9D,EAAM,WAAA+D,EAAY,YAAAC,EAAa,YAAAC,EAAa,WAAAC,EAAY,WAAAC,EAAY,SAAAC,EAAU,WAAAC,EAAY,SAAAC,EAAU,MAAAC,EAAO,MAAAC,EAAO,GAAGzF,CAAI,EAAKI,EAC1IsF,EAAcP,EACdQ,EAAW,CACT,YAAAV,EACA,YAAAC,EACA,WAAAC,EACA,WAAAC,EACA,SAAAL,EACA,QAASZ,EAAM,QACf,MAAOQ,EAAK,KACf,CAAA,EACC,CAAE,EACR,GAAIiB,EAA0BxF,CAAI,EAAG,CACjC,MAAMyE,EAAIgB,EAAwB,CAC9B,GAAG7F,EACH,SAAA+E,EACA,KAAA9D,EACA,MAAO0D,EAAK,MACZ,IAAKA,EAAK,IACV,QAASR,EAAM,QACf,MAAOG,EAAc,CAAClE,EAAKkE,CAAW,EAAImB,EAC1C,YAAAR,EACA,WAAAE,EACA,WAAAC,EACA,WAAAE,EACA,SAAAC,EACA,YAAAG,CACpB,CAAiB,EACGZ,EACAF,EAAkBE,CAAI,EAAE,KAAKD,CAAC,EAG1BiB,EAAc,eAACjB,EAAE,MAAOA,EAAE,IAAKR,EAAc,MAAOA,EAAc,GAAG,GACrEzB,EAAS,KAAK,IAAImD,EAAa,cAAC,CAAE,GAAI,GAAG,KAAK,EAAE,IAAIhB,CAAQ,GAAI,KAAMF,CAAG,CAAA,CAAC,CAGlG,MAEoBiB,EAAc,eAACnB,EAAK,MAAOA,EAAK,IAAKN,EAAc,MAAOA,EAAc,GAAG,GAC3EzB,EAAS,KAAK,IAAImD,gBAAc,CAC5B,GAAI,GAAG,KAAK,EAAE,IAAIhB,CAAQ,GAC1B,KAAM,CACF,GAAG/E,EACH,SAAA+E,EACA,KAAA9D,EACA,MAAO0D,EAAK,MACZ,MAAOL,EAAc,CAAClE,EAAKkE,CAAW,EAAImB,EAC1C,IAAKd,EAAK,IACV,QAASR,EAAM,QACf,YAAAuB,CACH,CACzB,CAAqB,CAAC,CAGtB,CACQ,OAAO,QAAQd,CAAiB,EAAE,IAAI,CAAC,CAACxD,EAAMsE,CAAW,IAAM,CAC3D,MAAMM,EAAIC,EAAAA,IAAIP,EAAY,IAAIb,GAAKA,EAAE,KAAK,CAAC,EACrChC,EAAIqD,EAAAA,IAAIR,EAAY,IAAIb,GAAKA,EAAE,GAAG,CAAC,EACzC,GAAIiB,EAAAA,eAAeE,EAAGnD,EAAGwB,EAAc,MAAOA,EAAc,GAAG,EAAG,CAC9D,KAAM,CAAE,SAAAU,EAAU,OAAAoB,GAAWT,EAAY,CAAC,EAC1C9C,EAAS,KAAK,IAAImD,gBAAc,CAC5B,GAAI,GAAG,KAAK,EAAE,IAAIhB,CAAQ,UAC1B,KAAM,CACF,KAAM,OACN,YAAAW,EACA,OAAAS,EACA,KAAA/E,EACA,MAAO4E,EACP,IAAKnD,EACL,QAASsB,EAAM,OAClB,CACrB,CAAiB,CAAC,CAClB,CACA,CAAS,EACDvB,EAAS,SAAU,CAC3B,CACI,YAAYuB,EAAOpE,EAAO,GAAI,CAC1B,OAAOqG,EAAiB,MAAOxD,GAAa,CACxC,GAAI,CACA,MAAM,KAAK,kBAAkBuB,EAAOpE,EAAM6C,EAAU,EAAI,CACxE,OACmBC,EAAG,CACND,EAAS,MAAMC,CAAC,CAChC,CACA,EAAW9C,EAAK,MAAM,CACtB,CACI,eAAgB,CAAA,CACpB","x_google_ignoreList":[0,1]}